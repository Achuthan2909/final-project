{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Setup and Data Loading\n",
    "\n",
    "## Purpose\n",
    "This notebook handles all setup, data loading, and model initialization. It prepares the data and extracts logits that will be used in all subsequent notebooks.\n",
    "\n",
    "## What This Notebook Does\n",
    "1. Import all necessary libraries\n",
    "2. Set random seeds for reproducibility\n",
    "3. Load CIFAR-10 dataset\n",
    "4. Load pre-trained ResNet56 model\n",
    "5. Extract logits and labels for validation and test sets\n",
    "6. Save preprocessed data for use in other notebooks\n",
    "\n",
    "## Output\n",
    "- `logits_val.npy` - Validation set logits\n",
    "- `labels_val.npy` - Validation set labels\n",
    "- `logits_test.npy` - Test set logits\n",
    "- `labels_test.npy` - Test set labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Metal (MPS)\n",
      "Device: mps\n",
      "PyTorch version: 2.9.1\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using Apple Metal (MPS)')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOAD PRE-TRAINED RESNET56 MODEL\n",
      "============================================================\n",
      "\u2713 ResNet56 loaded successfully\n",
      "  Parameters: 855,770\n",
      "  Model on device: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/Studies/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('STEP 1: LOAD PRE-TRAINED RESNET56 MODEL')\n",
    "print('='*60)\n",
    "\n",
    "try:\n",
    "    resnet_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True)\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    resnet_model.eval()\n",
    "    print('\u2713 ResNet56 loaded successfully')\n",
    "    print(f'  Parameters: {sum(p.numel() for p in resnet_model.parameters()):,}')\n",
    "    print(f'  Model on device: {next(resnet_model.parameters()).device}')\n",
    "except Exception as e:\n",
    "    print(f'\u2717 Failed to load model: {e}')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: LOAD CIFAR-10 DATASET\n",
      "============================================================\n",
      "\u2713 CIFAR-10 test set loaded\n",
      "  Total test samples: 10000\n",
      "  Number of classes: 10\n"
     ]
    }
   ],
   "source": "print('='*60)\nprint('STEP 2: LOAD CIFAR-10 DATASET')\nprint('='*60)\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n\nprint('\u2713 CIFAR-10 test set loaded')\nprint(f'  Total test samples: {len(testset)}')\nprint(f'  Number of classes: {len(testset.classes)}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: SPLIT DATA INTO VALIDATION AND TEST SETS\n",
      "============================================================\n",
      "\u2713 Data split completed\n",
      "  Validation set: 5000 samples\n",
      "  Test set: 5000 samples\n",
      "  Total: 10000 samples\n"
     ]
    }
   ],
   "source": "print('='*60)\nprint('STEP 3: SPLIT DATA INTO VALIDATION AND TEST SETS')\nprint('='*60)\n\nall_test_data = []\nall_test_labels = []\n\nwith torch.no_grad():\n    for images, labels in testloader:\n        all_test_data.append(images)\n        all_test_labels.append(labels)\n\nall_test_data = torch.cat(all_test_data, dim=0)\nall_test_labels = torch.cat(all_test_labels, dim=0)\n\nindices = np.arange(len(all_test_data))\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\nsplit_idx = len(indices) // 2\nval_indices = indices[:split_idx]\ntest_indices = indices[split_idx:]\n\nval_data = all_test_data[val_indices]\nval_labels = all_test_labels[val_indices]\ntest_data = all_test_data[test_indices]\ntest_labels = all_test_labels[test_indices]\n\nprint('\u2713 Data split completed')\nprint(f'  Validation set: {len(val_data)} samples')\nprint(f'  Test set: {len(test_data)} samples')\nprint(f'  Total: {len(val_data) + len(test_data)} samples')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: EXTRACT LOGITS AND LABELS\n",
      "============================================================\n",
      "Extracting logits from validation set...\n",
      "Extracting logits from test set...\n",
      "\n",
      "\u2713 Logits extracted successfully\n",
      "  Validation logits shape: (5000, 10)\n",
      "  Validation labels shape: (5000,)\n",
      "  Test logits shape: (5000, 10)\n",
      "  Test labels shape: (5000,)\n"
     ]
    }
   ],
   "source": "print('='*60)\nprint('STEP 4: EXTRACT LOGITS AND LABELS')\nprint('='*60)\n\nval_loader = DataLoader(torch.utils.data.TensorDataset(val_data, val_labels), batch_size=100, shuffle=False)\ntest_loader = DataLoader(torch.utils.data.TensorDataset(test_data, test_labels), batch_size=100, shuffle=False)\n\nlogits_val_list = []\nlabels_val_list = []\n\nprint('Extracting logits from validation set...')\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        logits = resnet_model(images)\n        logits_val_list.append(logits.cpu().numpy())\n        labels_val_list.append(labels.numpy())\n\nlogits_val = np.concatenate(logits_val_list, axis=0)\nlabels_val = np.concatenate(labels_val_list, axis=0)\n\nlogits_test_list = []\nlabels_test_list = []\n\nprint('Extracting logits from test set...')\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        logits = resnet_model(images)\n        logits_test_list.append(logits.cpu().numpy())\n        labels_test_list.append(labels.numpy())\n\nlogits_test = np.concatenate(logits_test_list, axis=0)\nlabels_test = np.concatenate(labels_test_list, axis=0)\n\nprint('\\n\u2713 Logits extracted successfully')\nprint(f'  Validation logits shape: {logits_val.shape}')\nprint(f'  Validation labels shape: {labels_val.shape}')\nprint(f'  Test logits shape: {logits_test.shape}')\nprint(f'  Test labels shape: {labels_test.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 5: SAVE PREPROCESSED DATA\n",
      "============================================================\n",
      "\u2713 Data saved successfully\n",
      "  Files saved to ./data/processed/\n",
      "  - logits_val.npy\n",
      "  - labels_val.npy\n",
      "  - logits_test.npy\n",
      "  - labels_test.npy\n",
      "\n",
      "============================================================\n",
      "SETUP COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Run Notebook 2: Baseline Calibration Methods\n",
      "  2. Or load saved data in other notebooks using:\n",
      "     logits_val = np.load(\"./data/processed/logits_val.npy\")\n",
      "     labels_val = np.load(\"./data/processed/labels_val.npy\")\n"
     ]
    }
   ],
   "source": "print('='*60)\nprint('STEP 5: SAVE PREPROCESSED DATA')\nprint('='*60)\n\nos.makedirs('./data/processed', exist_ok=True)\n\nnp.save('./data/processed/logits_val.npy', logits_val)\nnp.save('./data/processed/labels_val.npy', labels_val)\nnp.save('./data/processed/logits_test.npy', logits_test)\nnp.save('./data/processed/labels_test.npy', labels_test)\n\nprint('\u2713 Data saved successfully')\nprint('  Files saved to ./data/processed/')\nprint('  - logits_val.npy')\nprint('  - labels_val.npy')\nprint('  - logits_test.npy')\nprint('  - labels_test.npy')\nprint('\\n============================================================')\nprint('SETUP COMPLETE!')\nprint('============================================================')\nprint('\\nNext steps:')\nprint('  1. Run Notebook 2: Baseline Calibration Methods')\nprint('  2. Or load saved data in other notebooks using:')\nprint('     logits_val = np.load(\"./data/processed/logits_val.npy\")')\nprint('     labels_val = np.load(\"./data/processed/labels_val.npy\")')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}