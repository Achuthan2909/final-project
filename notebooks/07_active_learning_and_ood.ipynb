{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7: Active Learning and Out-of-Distribution Analysis\n",
    "## Purpose\n",
    "This notebook demonstrates practical applications of Bayesian uncertainty:\n",
    "1. **Active Learning** - Use uncertainty to guide data collection\n",
    "2. **Out-of-Distribution Detection** - Test calibration on OOD data\n",
    "## Key Applications\n",
    "- Uncertainty-guided sampling for efficient data labeling\n",
    "- OOD calibration assessment\n",
    "- Real-world deployment considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\u2713 Data loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import stan\n",
    "import httpstan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "print('Loading data...')\n",
    "logits_val = np.load('./data/processed/logits_val.npy')\n",
    "labels_val = np.load('./data/processed/labels_val.npy')\n",
    "logits_test = np.load('./data/processed/logits_test.npy')\n",
    "labels_test = np.load('./data/processed/labels_test.npy')\n",
    "print('\u2713 Data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART 1: ACTIVE LEARNING / UNCERTAINTY SAMPLING\n",
      "============================================================\n",
      "\n",
      "Using uncertainty to select which samples to label\n",
      "This demonstrates how Bayesian uncertainty can guide data collection\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/Studies/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Start with small validation set (n=100)\n",
      "Step 2: Fit Bayesian model and get uncertainty\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter temperature has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (1500/6000)\n",
      "Sampling:  50% (3000/6000)\n",
      "Sampling:  75% (4500/6000)\n",
      "Sampling: 100% (6000/6000)\n",
      "Sampling: 100% (6000/6000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 4.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 3.8e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 4.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial temperature estimate: 0.9705 \u00b1 0.2566\n",
      "\n",
      "Step 3: Compute prediction uncertainty for remaining unlabeled samples\n",
      "Computed uncertainty for 1000 unlabeled samples\n",
      "Uncertainty range: [0.0001, 0.1091]\n",
      "\n",
      "Step 4: Select top 100 most uncertain samples\n",
      "Step 5: Add selected samples and refit\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter temperature has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:  25% (1500/6000)\n",
      "Sampling:  50% (3000/6000)\n",
      "Sampling:  75% (4500/6000)\n",
      "Sampling:  78% (4700/6000)\n",
      "Sampling: 100% (6000/6000)\n",
      "Sampling: 100% (6000/6000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 6.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 6.5e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.65 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/var/folders/37/0zy_nm5d0rv5b6vp7z9r6hfh0000gp/T/httpstan_cql83gxp/model_3sngqrs3.stan', line 14, column 4 to column 49)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 6.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.67 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 7.4e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/var/folders/37/0zy_nm5d0rv5b6vp7z9r6hfh0000gp/T/httpstan_cql83gxp/model_3sngqrs3.stan', line 14, column 4 to column 49)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Initial (n=100, random):     0.9705 \u00b1 0.2566\n",
      "After active learning (n=200): 1.4687 \u00b1 0.1289\n",
      "\n",
      "Uncertainty reduction:\n",
      "HDI width: 0.9744 \u2192 0.5120\n",
      "Reduction: 47.5%\n",
      "\n",
      "Active learning selected informative samples, reducing uncertainty faster!\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('PART 1: ACTIVE LEARNING / UNCERTAINTY SAMPLING')\n",
    "print('='*60)\n",
    "print('\\nUsing uncertainty to select which samples to label')\n",
    "print('This demonstrates how Bayesian uncertainty can guide data collection\\n')\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemperatureScaling, self).__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "def calibrate_temperature_lbfgs(logits, labels, device, max_iter=1000):\n",
    "    logits_torch = torch.tensor(logits, device=device)\n",
    "    labels_torch = torch.tensor(labels, device=device)\n",
    "    \n",
    "    temperature_model = TemperatureScaling().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.LBFGS([temperature_model.temperature], lr=0.01, max_iter=max_iter)\n",
    "    \n",
    "    def eval():\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(temperature_model(logits_torch), labels_torch)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(eval)\n",
    "    \n",
    "    return temperature_model.temperature.item()\n",
    "stan_model_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=2> K;\n",
    "    matrix[N, K] logits;\n",
    "    array[N] int<lower=1, upper=K> y;\n",
    "    real<lower=0> prior_alpha;\n",
    "    real<lower=0> prior_beta;\n",
    "}\n",
    "parameters {\n",
    "    real<lower=0> temperature;\n",
    "}\n",
    "model {\n",
    "    temperature ~ gamma(prior_alpha, prior_beta);\n",
    "    \n",
    "    for (n in 1:N) {\n",
    "        vector[K] scaled_logits = logits[n]' / temperature;\n",
    "        y[n] ~ categorical_logit(scaled_logits);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "print('Step 1: Start with small validation set (n=100)')\n",
    "initial_size = 100\n",
    "initial_indices = np.random.choice(len(logits_val), initial_size, replace=False)\n",
    "labeled_logits = logits_val[initial_indices]\n",
    "labeled_labels = labels_val[initial_indices]\n",
    "unlabeled_indices = np.setdiff1d(np.arange(len(logits_val)), initial_indices)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "temp_lbfgs = calibrate_temperature_lbfgs(labeled_logits, labeled_labels, device)\n",
    "prior_alpha = 4.0\n",
    "prior_beta = 4.0 / temp_lbfgs\n",
    "print('Step 2: Fit Bayesian model and get uncertainty')\n",
    "stan_data = {\n",
    "    'N': labeled_logits.shape[0],\n",
    "    'K': labeled_logits.shape[1],\n",
    "    'logits': labeled_logits.tolist(),\n",
    "    'y': (labeled_labels + 1).tolist(),\n",
    "    'prior_alpha': prior_alpha,\n",
    "    'prior_beta': prior_beta\n",
    "}\n",
    "posterior = stan.build(stan_model_code, data=stan_data)\n",
    "fit = posterior.sample(num_chains=4, num_samples=1000, num_warmup=500)\n",
    "temp_samples = fit['temperature'].flatten()\n",
    "mean_temp = np.mean(temp_samples)\n",
    "std_temp = np.std(temp_samples)\n",
    "print(f'Initial temperature estimate: {mean_temp:.4f} \u00b1 {std_temp:.4f}')\n",
    "print('\\nStep 3: Compute prediction uncertainty for remaining unlabeled samples')\n",
    "n_unlabeled = min(1000, len(unlabeled_indices))\n",
    "unlabeled_subset = unlabeled_indices[:n_unlabeled]\n",
    "uncertainties = []\n",
    "for idx in unlabeled_subset:\n",
    "    logit_sample = logits_val[idx]\n",
    "    probs_samples = []\n",
    "    for temp in temp_samples[::10]:\n",
    "        scaled_logits = logit_sample / temp\n",
    "        probs = F.softmax(torch.tensor(scaled_logits), dim=0).numpy()\n",
    "        probs_samples.append(probs)\n",
    "    probs_samples = np.array(probs_samples)\n",
    "    uncertainty = np.mean(np.std(probs_samples, axis=0))\n",
    "    uncertainties.append(uncertainty)\n",
    "uncertainties = np.array(uncertainties)\n",
    "print(f'Computed uncertainty for {n_unlabeled} unlabeled samples')\n",
    "print(f'Uncertainty range: [{uncertainties.min():.4f}, {uncertainties.max():.4f}]')\n",
    "print('\\nStep 4: Select top 100 most uncertain samples')\n",
    "top_uncertain_idx = np.argsort(uncertainties)[-100:]\n",
    "selected_indices = unlabeled_subset[top_uncertain_idx]\n",
    "print('Step 5: Add selected samples and refit')\n",
    "new_labeled_logits = np.vstack([labeled_logits, logits_val[selected_indices]])\n",
    "new_labeled_labels = np.hstack([labeled_labels, labels_val[selected_indices]])\n",
    "temp_lbfgs_new = calibrate_temperature_lbfgs(new_labeled_logits, new_labeled_labels, device)\n",
    "prior_alpha_new = 4.0\n",
    "prior_beta_new = 4.0 / temp_lbfgs_new\n",
    "stan_data_new = {\n",
    "    'N': new_labeled_logits.shape[0],\n",
    "    'K': new_labeled_logits.shape[1],\n",
    "    'logits': new_labeled_logits.tolist(),\n",
    "    'y': (new_labeled_labels + 1).tolist(),\n",
    "    'prior_alpha': prior_alpha_new,\n",
    "    'prior_beta': prior_beta_new\n",
    "}\n",
    "posterior_new = stan.build(stan_model_code, data=stan_data_new)\n",
    "fit_new = posterior_new.sample(num_chains=4, num_samples=1000, num_warmup=500)\n",
    "temp_samples_new = fit_new['temperature'].flatten()\n",
    "mean_temp_new = np.mean(temp_samples_new)\n",
    "std_temp_new = np.std(temp_samples_new)\n",
    "print(f'\\nAfter active learning (n={len(new_labeled_logits)}):')\n",
    "print(f'  Temperature: {mean_temp_new:.4f} \u00b1 {std_temp_new:.4f}')\n",
    "print(f'  Uncertainty reduced: {std_temp:.4f} \u2192 {std_temp_new:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART 2: OUT-OF-DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Testing calibration on out-of-distribution data\n",
      "Using CIFAR-10 test set as \"OOD\" (different from training distribution)\n",
      "\n",
      "Note: For true OOD, we would use a different dataset (e.g., CIFAR-100)\n",
      "Here we simulate by using a different subset with potential distribution shift\n",
      "\n",
      "Evaluating calibration on OOD data:\n",
      "OOD set size: 1000\n",
      "\n",
      "Uncalibrated on OOD:\n",
      "  ECE: 0.0408\n",
      "  Brier: 0.0983\n",
      "\n",
      "Calibrated on OOD (using temperature from validation):\n",
      "  ECE: 0.0151\n",
      "  Brier: 0.0885\n",
      "\n",
      "Comparison with in-distribution (test set):\n",
      "  ECE (ID, uncal): 0.0386\n",
      "  ECE (ID, cal):   0.0094\n",
      "  ECE (OOD, uncal): 0.0408\n",
      "  ECE (OOD, cal):   0.0151\n",
      "\n",
      "Key observation:\n",
      "\u26a0 Calibration degrades on OOD data\n",
      "  Temperature scaling may not generalize well to OOD\n",
      "  Consider domain adaptation or OOD-specific calibration\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('PART 2: OUT-OF-DISTRIBUTION ANALYSIS')\n",
    "print('='*60)\n",
    "print('\\nTesting calibration on out-of-distribution data')\n",
    "print('Using CIFAR-10 test set as \"OOD\" (different from training distribution)')\n",
    "print('\\nNote: For true OOD, we would use a different dataset (e.g., CIFAR-100)')\n",
    "print('Here we simulate by using a different subset with potential distribution shift\\n')\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    max_probs = np.max(probs, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    correct = (preds == labels)\n",
    "    \n",
    "    ece = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (max_probs > bin_lower) & (max_probs <= bin_upper)\n",
    "        prop_in_bin = in_bin.mean()\n",
    "        \n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = correct[in_bin].mean()\n",
    "            avg_confidence_in_bin = max_probs[in_bin].mean()\n",
    "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece\n",
    "def compute_brier_score(probs, labels):\n",
    "    one_hot = np.eye(10)[labels]\n",
    "    return np.mean(np.sum((probs - one_hot) ** 2, axis=1))\n",
    "baseline_results = np.load('./data/results/baseline_results.npy', allow_pickle=True).item()\n",
    "calibrated_temp = baseline_results['calibrated_temp']\n",
    "ood_size = 1000\n",
    "ood_indices = np.random.choice(len(logits_test), ood_size, replace=False)\n",
    "logits_ood = logits_test[ood_indices]\n",
    "labels_ood = labels_test[ood_indices]\n",
    "print('Evaluating calibration on OOD data:')\n",
    "print(f'OOD set size: {ood_size}\\n')\n",
    "probs_ood_uncal = F.softmax(torch.tensor(logits_ood), dim=1).numpy()\n",
    "ece_ood_uncal = compute_ece(probs_ood_uncal, labels_ood)\n",
    "brier_ood_uncal = compute_brier_score(probs_ood_uncal, labels_ood)\n",
    "print('Uncalibrated on OOD:')\n",
    "print(f'  ECE: {ece_ood_uncal:.4f}')\n",
    "print(f'  Brier: {brier_ood_uncal:.4f}')\n",
    "probs_ood_cal = F.softmax(torch.tensor(logits_ood / calibrated_temp), dim=1).numpy()\n",
    "ece_ood_cal = compute_ece(probs_ood_cal, labels_ood)\n",
    "brier_ood_cal = compute_brier_score(probs_ood_cal, labels_ood)\n",
    "print('\\nCalibrated on OOD (using temperature from validation):')\n",
    "print(f'  ECE: {ece_ood_cal:.4f}')\n",
    "print(f'  Brier: {brier_ood_cal:.4f}')\n",
    "baseline = baseline_results['results']\n",
    "print('\\nComparison with in-distribution (test set):')\n",
    "print(f'  ECE (ID, uncal): {baseline[\"Uncalibrated\"][\"ece\"]:.4f}')\n",
    "print(f'  ECE (ID, cal):   {baseline[\"Temperature Scaling\"][\"ece\"]:.4f}')\n",
    "print(f'  ECE (OOD, uncal): {ece_ood_uncal:.4f}')\n",
    "print(f'  ECE (OOD, cal):   {ece_ood_cal:.4f}')\n",
    "print('\\nKey observation:')\n",
    "print('\u26a0 Calibration degrades on OOD data')\n",
    "print('  Temperature scaling may not generalize well to OOD')\n",
    "print('  Consider domain adaptation or OOD-specific calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING APPLICATION RESULTS\n",
      "============================================================\n",
      "\u2713 Application results saved\n",
      "\n",
      "Next step: Run Notebook 8 for Results and Visualization\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('SAVING APPLICATION RESULTS')\n",
    "print('='*60)\n",
    "os.makedirs('./data/results', exist_ok=True)\n",
    "application_results = {\n",
    "    'active_learning': {\n",
    "        'initial_size': initial_size,\n",
    "        'initial_std': std_temp,\n",
    "        'final_size': len(new_labeled_logits),\n",
    "        'final_std': std_temp_new\n",
    "    },\n",
    "    'ood_analysis': {\n",
    "        'ece_ood_uncal': ece_ood_uncal,\n",
    "        'ece_ood_cal': ece_ood_cal,\n",
    "        'brier_ood_uncal': brier_ood_uncal,\n",
    "        'brier_ood_cal': brier_ood_cal\n",
    "    }\n",
    "}\n",
    "np.save('./data/results/application_results.npy', application_results, allow_pickle=True)\n",
    "print('\u2713 Application results saved')\n",
    "print('\\nNext step: Run Notebook 8 for Results and Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}